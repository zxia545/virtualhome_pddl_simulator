{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory containing the JSON files\n",
    "directory_path = './data_folder_gpt4_entropy_three_prompt'\n",
    "\n",
    "# Function to count words and punctuation\n",
    "def count_words_and_punctuation(output):\n",
    "    words_and_punct = re.findall(r'\\w+|[,.!]', output)\n",
    "    return len(words_and_punct)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word count greater than 2000: 3013\n",
      "Entropy vs Word Count for Wizardlm\n",
      "Entropy vs Word Count for Koala\n",
      "Entropy vs Word Count for Lima\n",
      "Entropy vs Word Count for Alpaca\n",
      "Entropy vs Word Count for Vicuna\n",
      "Entropy vs Word Count for Sinstruct\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "darker_blue = '#4682B4'  # Slightly darker shade of blue\n",
    "# Function to count words and punctuation\n",
    "def count_words_and_punctuation(text):\n",
    "    # Replace this with your word and punctuation counting logic\n",
    "    return len(text.split())\n",
    "\n",
    "# Function to load and process data\n",
    "def process_data(directory_path):\n",
    "    data_by_dataset = {}\n",
    "    \n",
    "    # Iterate through each file in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.json'):\n",
    "            parts = filename.split('_')\n",
    "            if 'same_length' in filename:\n",
    "                dataset = parts[2]\n",
    "            else:\n",
    "                dataset = parts[0]\n",
    "            \n",
    "            if 'concise' in filename:\n",
    "                method = 'concise' \n",
    "            elif 'detailed' in filename:\n",
    "                method = 'detailed'\n",
    "            elif 'reference' in filename:\n",
    "                method = 'original'\n",
    "            \n",
    "            # Load JSON data\n",
    "            with open(os.path.join(directory_path, filename), 'r') as file:\n",
    "                data = json.load(file)\n",
    "            \n",
    "            # Extract data and calculate word counts\n",
    "            for item in data:\n",
    "                entropy_score = item['entropy_score']\n",
    "                word_count = count_words_and_punctuation(item['output'])\n",
    "                \n",
    "                if word_count > 2000:\n",
    "                    print(f'Word count greater than 2000: {word_count}')\n",
    "                    continue\n",
    "                else:\n",
    "                    # Organize data by dataset\n",
    "                    if dataset not in data_by_dataset:\n",
    "                        data_by_dataset[dataset] = {'x': [], 'y': [], 'labels': []}\n",
    "                    \n",
    "                    if method == 'original':\n",
    "                        data_by_dataset[dataset]['x'].append(word_count)\n",
    "                        data_by_dataset[dataset]['y'].append(entropy_score)\n",
    "                        data_by_dataset[dataset]['labels'].append(method)\n",
    "    \n",
    "    return data_by_dataset\n",
    "\n",
    "# Plotting function\n",
    "def plot_data_to_pdf(data_by_dataset, output_pdf):\n",
    "\n",
    "    # Create a plot for each dataset\n",
    "    for dataset, data in data_by_dataset.items():\n",
    "        real_output_pdf = dataset[0].lower()+ dataset[1:] + output_pdf\n",
    "        with PdfPages(real_output_pdf) as pdf:\n",
    "            plt.figure(figsize=(4, 2.5))\n",
    "            plt.scatter(\n",
    "                data['x'], \n",
    "                data['y'], \n",
    "                c=[{'original': darker_blue}[label] for label in data['labels']], \n",
    "                alpha=0.5\n",
    "            )\n",
    "            dataset_name = dataset[0].upper() + dataset[1:]\n",
    "            print(f'Entropy vs Word Count for {dataset_name}')\n",
    "            \n",
    "            plt.xlabel('Word Count', fontsize=12)\n",
    "            plt.ylabel('Information Mass', fontsize=12)\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            # Set legend to always appear at the bottom right\n",
    "            # plt.legend(handles=[plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='lightblue', markersize=5, label='Original')], loc='lower right')\n",
    "            # Save the current figure to the PDF\n",
    "            pdf.savefig()  # Saves the current figure into the PDF\n",
    "            plt.close()\n",
    "\n",
    "# Directory path and output file\n",
    "directory_path = './data_folder_gpt4_entropy_three_prompt'  # Replace with your directory path\n",
    "output_pdf = '_entropy_word_count.pdf'\n",
    "\n",
    "# Process the data and generate PDF\n",
    "data_by_dataset = process_data(directory_path)\n",
    "plot_data_to_pdf(data_by_dataset, output_pdf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
